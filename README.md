# FAQ-Generation-for-Telehealth-Platforms

## Introduction

This project adapts the FLAN-T5 family (Small, Base, Large, XL) for **telehealth Q&A** using **parameter-efficient fine-tuning (LoRA/PEFT)** on a cleaned subset of MedDialog (English). The goal is to generate **concise, non-prescriptive** doctor-style responses to patient prompts while operating within realistic compute limits. I engineered a deterministic data pipeline (role normalisation, malformed/one-turn removal, 10–100-word filter for doctor replies) and a fixed-seed 80/20 train/benchmark split, then fine-tuned FLAN-T5 with targeted LoRA adapters and decoding controls (beam search, repetition penalty, n-gram blocking, capped length). To improve controllability, the system supports **intent-aware prompts**—*general*, *diagnosis*, *psychological*, and *medication*—each embedding safety language and “seek professional care” guidance.

Evaluation combines **ROUGE-1/2/L** (lexical overlap) and **BERTScore-F1** (semantic alignment). On the benchmark slice, the FLAN-T5-Base LoRA model shows large absolute gains over the pretrained baseline (e.g., ROUGE-1 **0.0478 → 0.4143**, ROUGE-2 **0.0060 → 0.2189**, ROUGE-L **0.0419 → 0.3663**, BERTScore-F1 **0.8380 → 0.9025**), with **consistent improvements across intents** on a held-out test set. The repository includes one notebook per tier—`flan-t5-small/base/large/xl.ipynb`—following a shared workflow (data → LoRA fine-tune → eval → plots) and writing reproducible artefacts (CSVs, curves, comparison charts). Overall, this project demonstrates a **safe, reproducible, and compute-efficient** path to domain adaptation for clinical-style dialogue, suitable for teaching, benchmarking, and future extensions.
